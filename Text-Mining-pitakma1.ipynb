{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import wikipedia\n",
    "import re\n",
    "\n",
    "from nltk import Tree\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenCounts(tokens):\n",
    "    counts = Counter(tokens)\n",
    "    sortedCounts = sorted(counts.items(), key=lambda count:count[1], reverse=True)\n",
    "    return sortedCounts\n",
    "\n",
    "def extractEntities(ne_chunked):\n",
    "    data = {}\n",
    "    for entity in ne_chunked:\n",
    "        if isinstance(entity, nltk.tree.Tree):\n",
    "            text = \" \".join([word for word, tag in entity.leaves()])\n",
    "            ent = entity.label()\n",
    "            data[text] = ent\n",
    "        else:\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"text.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook, The Drunkard, by Cyril Arthur Edward Ranger\n",
      "Gull\n",
      "\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Title: The Drunkard\n",
      "\n",
      "\n",
      "Author: Cyril Arthur Edward Ranger Gull\n",
      "\n",
      "\n",
      "\n",
      "Release Date: October 22, 2012  [eBook #41139]\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "***START OF THE PROJECT GUTENBERG\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "tokens = nltk.word_tokenize(text)\n",
    " \n",
    "filtered_tokens = [token for token in tokens if token not in punctuation]\n",
    "filtered_tokens = [token for token in filtered_tokens if token not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9325"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    " \n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged_filtered = nltk.pos_tag(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered: [('The', 'DT'), ('Project', 'NNP'), ('Gutenberg', 'NNP'), ('eBook', 'NN'), (',', ','), ('The', 'DT'), ('Drunkard', 'NNP'), (',', ','), ('by', 'IN'), ('Cyril', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unfiltered:\",tagged[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered: [('The', 'DT'), ('Project', 'NNP'), ('Gutenberg', 'NNP'), ('eBook', 'VBD'), ('The', 'DT'), ('Drunkard', 'NNP'), ('Cyril', 'NNP'), ('Arthur', 'NNP'), ('Edward', 'NNP'), ('Ranger', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(\"filtered:\",tagged_filtered[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_chunked = nltk.ne_chunk(tagged_filtered, binary=True)\n",
    "nre = extractEntities(ne_chunked)\n",
    "len(nre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Audience': 'NE',\n",
       " 'Grand Duke Alexis': 'NE',\n",
       " 'Greek Euripidean': 'NE',\n",
       " 'Helena': 'NE',\n",
       " 'Lord Quinton': 'NE',\n",
       " 'Mr. Helzephron': 'NE',\n",
       " 'Mr. Rockefeller': 'NE',\n",
       " 'PROJECT': 'NE',\n",
       " 'Prison': 'NE',\n",
       " 'Rockefeller American': 'NE'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{a:nre[a] for a in list(nre.keys())[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_chunked_false = nltk.ne_chunk(tagged_filtered, binary=False)\n",
    "nre_class = extractEntities(ne_chunked_false)\n",
    "len(nre_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Audience': 'ORGANIZATION',\n",
       " 'Grand Duke Alexis': 'FACILITY',\n",
       " 'Hands': 'PERSON',\n",
       " 'Helena': 'PERSON',\n",
       " 'Hood': 'PERSON',\n",
       " 'III': 'ORGANIZATION',\n",
       " 'PROJECT': 'ORGANIZATION',\n",
       " 'Spring Partner': 'PERSON',\n",
       " 'St.': 'ORGANIZATION',\n",
       " 'Well': 'PERSON'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{a:nre_class[a] for a in list(nre_class.keys())[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4463"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_nre = []\n",
    "entity = []\n",
    "for tagged_entry in tagged:\n",
    "    if(tagged_entry[1].startswith(\"NN\") or (entity and tagged_entry[1].startswith(\"IN\"))):\n",
    "        entity.append(tagged_entry)\n",
    "    else:\n",
    "        if(entity and entity[-1][1].startswith(\"IN\")):\n",
    "            entity.pop()\n",
    "        if(entity and \" \".join(e[0] for e in entity)[0].isupper()):\n",
    "           custom_nre.append(\" \".join(e[0] for e in entity))\n",
    "        entity = []\n",
    "len(custom_nre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Gutenberg eBook',\n",
       " 'Drunkard',\n",
       " 'Cyril Arthur Edward Ranger Gull',\n",
       " 'Project Gutenberg License',\n",
       " 'Title',\n",
       " 'Drunkard Author',\n",
       " 'Cyril Arthur Edward Ranger Gull Release Date',\n",
       " 'October',\n",
       " 'Language',\n",
       " 'Mark C. Orton']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_nre[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Quinton: moral philosopher\n",
      "Grand Duke Alexis: the fifth child\n",
      "Audience: An audience\n",
      "Mr. Helzephron: An object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /usr/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Rockefeller: an American oil industry\n",
      "PROJECT: contemporary business\n",
      "Prison: A prison\n",
      "Helena: the state capital\n",
      "Rockefeller American: an American oil industry\n",
      "Greek Euripidean: An object\n"
     ]
    }
   ],
   "source": [
    "limit = 10\n",
    "for key in nre.keys():\n",
    "    try:\n",
    "        page = wikipedia.page(key)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        page = wikipedia.page(e.options[0])\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        page = wikipedia.page(\"Object (philosophy)\")\n",
    "    summary = re.sub(\"\\([^\\)]*\\)|\\[\\w*\\]\", \"\", page.summary)\n",
    "    summary = re.sub(key, \"\", summary)\n",
    "    summary = nltk.sent_tokenize(summary)\n",
    "    summary = nltk.word_tokenize(summary[0])\n",
    "    summary = nltk.pos_tag(summary)\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>(<IN>?<DT>?<JJ>*(<NN>|<NNP>*))?}\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(summary)\n",
    "    for child in result:\n",
    "        if isinstance(child, Tree):               \n",
    "            if child.label() == 'NP':\n",
    "                print(\"{}:\".format(key), \" \".join(e[0] for e in child.leaves()))\n",
    "                break\n",
    "    limit -= 1\n",
    "    if limit == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg eBook: a volunteer effort\n",
      "Drunkard: Alcoholism\n",
      "Cyril Arthur Edward Ranger Gull: the pen name of\n",
      "Project Gutenberg License: action film\n",
      "Title: A title\n",
      "Drunkard Author: an American temperance play\n",
      "Cyril Arthur Edward Ranger Gull Release Date: an educational film production\n",
      "October: the tenth month of the year\n",
      "Language: a system\n",
      "Mark C. Orton: an American composer\n"
     ]
    }
   ],
   "source": [
    "limit = 10\n",
    "for key in custom_nre:\n",
    "    try:\n",
    "        page = wikipedia.page(key)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        page = wikipedia.page(e.options[0])\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        page = wikipedia.page(\"Object (philosophy)\")\n",
    "    summary = re.sub(\"\\([^\\)]*\\)|\\[\\w*\\]\", \"\", page.summary)\n",
    "    summary = re.sub(key, \"\", summary)\n",
    "    summary = nltk.sent_tokenize(summary)\n",
    "    summary = nltk.word_tokenize(summary[0])\n",
    "    summary = nltk.pos_tag(summary)\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>(<IN>?<DT>?<JJ>*(<NN>|<NNP>*))?}\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(summary)\n",
    "    for child in result:\n",
    "        if isinstance(child, Tree):               \n",
    "            if child.label() == 'NP':\n",
    "                print(\"{}:\".format(key), \" \".join(e[0] for e in child.leaves()))\n",
    "                break\n",
    "    limit -= 1\n",
    "    if limit == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
